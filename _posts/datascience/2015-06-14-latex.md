---
layout: post
title: " 一些公式"
keywords: ["ML","mechine learning","SVM","","Dtree","classification"]
description: "svm"
category: "Datascience"
tags: ["ML","Datascience"]
---


### 平均值  mean

$$
E(x)=\frac{1}{n}(x_1+x_2+\cdots+x_n)
$$


### 方差(Variance)

$$
D(X)=s^2=\frac{1}{n}\sum_{i=1}^{n}{(x_i - \overline{x})^2}
$$

### 标准差

$$
s=\sqrt{ \frac{1}{n}\sum_{i=1}^{n}{(x_i - \overline{x})^2} }
$$

### 方差D(x)与期望值E(X)之间的关系

$$
D(x)=E(X^2)-E(X)^2
$$

Gradient Descent (SGD BGD)
牛顿法
拟牛顿法
BGFS
L-BGFS


### 决策树

ID3,C4.5  信息增益(最大信息增益)/信息增益率 

CART  基尼系数Gini 最好的划分就是使得GINI_Gain最小的划分。（回归树：最小平方残差、最小绝对残差等）
