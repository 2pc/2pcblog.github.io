---
layout: post
title: "Mechine learning notes"
keywords: ["ML","mechine learning","SVM","","Dtree","classification"]
description: "svm"
category: "Datascience"
tags: ["ML","Datascience"]
---

### 梯度下降与回归方法

>
从中心极限定理到正太分布到极大释然函数到平方和最小函数能求解出最佳theta
批量梯度：每次迭代计算theta使用所有样本
随机梯度：没读取一条样本就迭代对theta进行更新



### 逻辑回归 softmax

>
Gradient Descent (SGD BGD)
牛顿法
拟牛顿法
BGFS
L-BGFS


### 决策树

>
ID3,C4.5  信息增益(最大信息增益)/信息增益率 

CART  基尼系数Gini 最好的划分就是使得GINI_Gain最小的划分。（回归树：最小平方残差、最小绝对残差等）
